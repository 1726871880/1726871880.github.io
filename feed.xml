<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://1726871880.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://1726871880.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2023-10-20T10:59:34+00:00</updated><id>https://1726871880.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">线性模型中R²、r、η²、f²、f、F的关系</title><link href="https://1726871880.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR-r-%CE%B7-f-f-F%E7%9A%84%E5%85%B3%E7%B3%BB/" rel="alternate" type="text/html" title="线性模型中R²、r、η²、f²、f、F的关系"/><published>2023-09-16T16:40:16+00:00</published><updated>2023-09-16T16:40:16+00:00</updated><id>https://1726871880.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR%C2%B2%E3%80%81r%E3%80%81%CE%B7%C2%B2%E3%80%81f%C2%B2%E3%80%81f%E3%80%81F%E7%9A%84%E5%85%B3%E7%B3%BB</id><content type="html" xml:base="https://1726871880.github.io/blog/2023/%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E4%B8%ADR-r-%CE%B7-f-f-F%E7%9A%84%E5%85%B3%E7%B3%BB/"><![CDATA[<p>决定系数 \(R^2\) 原本的含义是拟合优度。</p> <p>具体来讲，在回归分析中，我们将全部观测值 \(y_i\) 偏离均值 \(\bar{y}\) 的离差平方和记作SST(Sum of Squares Total)。其中包含了观测值 \(y_i\) 偏离回归估计值 \(\hat{y_i}\) 离差平方和SSE(Sum of Squares Error)，以及估计值 \(\hat{y_i}\) 偏离平均值 \(\bar{y}\) 的离差平方和SSR(Sum of Squares Regression)。</p> \[\begin{eqnarray} SST &amp; = &amp; \sum_{i=1}^{n} (y_i-\bar{y})^2\\ &amp; = &amp; \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})+(y_i-\hat{y})]^2\\ &amp; = &amp; \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})^2+(y_i-\hat{y})^2+2(\hat{y_i}-\bar{y})(y_i-\hat{y})]\\ \end{eqnarray}\] <p>回归模型的外生性假设要求误差项与解释变量不相关，即 \(Cov(X,\varepsilon) = 0\)，我们知道回归的基本表达是 \(\hat{y_i} = b_0 + b_1 x_i\)，所以\(Cov(\hat{Y},\varepsilon) = 0\)。所以：</p> \[\begin{eqnarray} \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})^2+(y_i-\hat{y})^2+2(\hat{y_i}-\bar{y})(y_i-\hat{y})] = \sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2+ \sum_{i=1}^{n} (y_i-\hat{y})^2 = SSR + SSE \end{eqnarray}\] <p>SSE代表回归方程无法解释的变异，SSR代表回归方程可以解释的变异。SSR/SST，即可解释变异占总变异的比例，代表了回归方程的拟合优度，即 \(R^2\)。决定系数 \(R^2\) 实际上就是样本皮尔逊相关系数 \(r\) 的平方。根据 \(r\) 的计算公式很容易得到：</p> \[\begin{eqnarray} r^2 &amp; = &amp; \left[ \frac{Cov(X, Y)}{\sigma(x)\sigma(y)}\right]^2 &amp; = &amp; \frac{\left[ \sum_{i=1}^{n}(y_i-\bar{y})(x_i-\bar{x}) \right]^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2\sum_{i=1}^{n}(x_i-\bar{x})^2} \end{eqnarray}\] <p>单独拿出分子:</p> \[\begin{eqnarray} &amp;&amp; [\sum_{i=1}^{n}(y_i-\bar{y})(x_i-\bar{x})]^2\\ &amp; = &amp; [\sum_{i=1}^{n}[(y_i-\hat{y_i})+(\hat{y_i}-\bar{y})](x_i-\bar{x})]^2\\ &amp; = &amp; [\sum_{i=1}^{n}(y_i-\hat{y_i})(x_i-\bar{x})+ \sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2 \end{eqnarray}\] <p>单独拿出括号中的左半部分 \(\sum_{i=1}^{n}(y_i-\hat{y_i})(x_i-\bar{x})\)，我们知道回归的基本表达是 \(\hat{y_i} = b_0 + b_1 x_i\)，代入得到：</p> \[\begin{eqnarray} &amp;&amp; \sum_{i=1}^{n}(y_i-\hat{y})(x_i-\bar{x})\\ &amp; = &amp; \frac{1}{b_1}\sum_{i=1}^{n}(y_i-\hat{y_i})[(b_1 x_i+b_0)-(b_1\bar{x}+b_0)]\\ &amp; = &amp; \frac{1}{b_1}\sum_{i=1}^{n}(y_i-\hat{y_i})(\hat{y_i}-\bar{y}) \end{eqnarray}\] <p>与 (4) 同理，根据回归分析的外生性假设，(11) 可以直接消掉，(8) 只剩下 \([\sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2\)。然后同理将 \(y = b_0 + b_1x\) 代入:</p> \[\begin{eqnarray} &amp;&amp; [\sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x})]^2\\ &amp; = &amp; \sum_{i=1}^{n}(\hat{y_i}-\bar{y})(x_i-\bar{x}) \sum_{i=1}^{n}(\hat{y}-\bar{y})(x_i-\bar{x})\\ &amp; = &amp; \frac{1}{b} \sum_{i=1}^{n} [(\hat{y_i}-\bar{y})]^2 b\sum_{i=1}^{n}[(x_i-\bar{x})]^2 \\ &amp; = &amp; \sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2 \sum_{i=1}^{n} (x_i-\bar{x})^2 \end{eqnarray}\] <p>那么(5)变为：</p> \[\begin{eqnarray} &amp;&amp; \frac{\sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2 \sum_{i=1}^{n} (x_i-\bar{x})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2\sum_{i=1}^{n}(x_i-\bar{x})^2} &amp; = &amp; \frac{\sum_{i=1}^{n} (\hat{y_i}-\bar{y})^2}{\sum_{i=1}^{n}(y_i-\bar{y})^2} &amp; = &amp; \frac{SSR}{SST} &amp; = &amp; R^2 \end{eqnarray}\] <p>而且 \(r^2\) 同时也是方差分析中常用的效应量 \(\eta^2\)。方差分析是观测变量为分类变量的线性模型，上面证明中的SSE对应方差分析中的组间离差平方和，SSR对应组内离差平方和。</p> <p>有了 \(r^2\) 后，我们就可以计算 \(f^2\)，常见的公式是：</p> \[\begin{eqnarray} f^2 = \frac{r^2}{1-r^2} \end{eqnarray}\] <p>加上根号就可以得到 \(f\) 的公式。 习惯上把 \(f=0.1, 0.25, 0.4\)分别算作小、中、大效应。那么 \(f^2\) 的小、中、大效应应该分别是0.01，0.0625和0.16，而不是很多资料中指定的0.02，0.15和0.35。用Gpower算样本量，如果按照0.15的中等效应量，算出来的样本量会非常少，用0.06算会看起来合理一些。不过这个争论这个问题意义不大，一方面效应量的划分本来就是非常武断的，另一方面几乎没有人会用 \(f\) 或 \(f^2\) 报告效应量。比较合理的方式是根据过去类似研究确定样本量，然后计算如此样本量最小能检测到多大的效应。</p> <p>我们进一步推导。因为</p> \[\begin{eqnarray} r^2 = \frac{SSR}{SST} = \frac{SST-SSE}{SST} = 1-\frac{SSE}{SST} \end{eqnarray}\] <p>所以\(f^2\) 的含义实际上是：</p> \[\begin{eqnarray} f^2 = \frac{\frac{SSR}{SST}}{1-(1-\frac{SSE}{SST})} = \frac{SSR}{SSE} \end{eqnarray}\] <p>所以 \(f^2\) 也是一种拟合优度的指标，含义是回归模型可解释变异与不可解释变异的比值。</p> <p>但 \(f^2\) 和 \(R^2\) 不能直接进行检验，此时就需要引出 \(F\)。 \(F\) 是一个类似于 \(f^2\) 的效应值，区别在于 \(F\) 考虑了自由度，因此可以根据 \(F\) 分布进行假设检验:</p> \[\begin{eqnarray} F = \frac{SSR/1}{SSE/(n-2)} \end{eqnarray}\] <p>可以看出 \(F\) 就是在 \(f^2\) 的基础上，分子分母同时除以自由度。上面的式子是一元回归的情况，多元回归时，分子自由度为 \(k\) ，分母自由度为 \(n-k-1\) ， \(k\) 是预测变量的个数。</p>]]></content><author><name></name></author><category term="心理学"/><summary type="html"><![CDATA[这些效应值实际上都是不同版本的回归模型拟合优度。]]></summary></entry><entry><title type="html">Displaying External Posts on Your al-folio Blog</title><link href="https://1726871880.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/" rel="alternate" type="text/html" title="Displaying External Posts on Your al-folio Blog"/><published>2022-04-23T23:20:09+00:00</published><updated>2022-04-23T23:20:09+00:00</updated><id>https://1726871880.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog</id><content type="html" xml:base="https://1726871880.github.io/blog/2022/displaying-external-posts-on-your-al-folio-blog/"><![CDATA[]]></content><author><name></name></author></entry></feed>